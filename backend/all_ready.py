#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
çµä¾æ™ºèƒ½ä½“ç³»ç»Ÿ - æ¨¡å‹ä¸æ•°æ®ä¸€é”®å®‰è£…è„šæœ¬
===========================================

åŠŸèƒ½ç‰¹æ€§ï¼š
1. TTSæ¨¡å‹æ£€æµ‹ä¸ä¸‹è½½ï¼ˆGenie-TTSï¼‰
2. ASRæ¨¡å‹æ£€æµ‹ä¸ä¸‹è½½ï¼ˆFunASR-Nanoï¼‰
3. æ™ºèƒ½ä¸‹è½½æœºåˆ¶
4. æ–­ç‚¹ç»­ä¼ æ”¯æŒ
5. é…ç½®è¯»å–ä¸éªŒè¯
6. å½©è‰²ç»ˆç«¯è¾“å‡ºä¸è¿›åº¦æ¡æ˜¾ç¤º
7. é”™è¯¯å¤„ç†ä¸æ¢å¤
8. é‡å¤å®‰è£…æ£€æµ‹

Usage:
    python all_ready.py                    # æ£€æµ‹å¹¶å®‰è£…æ‰€æœ‰ç¼ºå¤±çš„æ¨¡å‹
    python all_ready.py --tts-only         # ä»…æ£€æµ‹å’Œå®‰è£…TTSæ¨¡å‹
    python all_ready.py --asr-only         # ä»…æ£€æµ‹å’Œå®‰è£…ASRæ¨¡å‹
    python all_ready.py --force            # å¼ºåˆ¶é‡æ–°å®‰è£…æ‰€æœ‰æ¨¡å‹
    python all_ready.py --check-only       # ä»…æ£€æµ‹ï¼Œä¸æ‰§è¡Œä¸‹è½½
"""

import argparse
import json
import os
import sys
import time
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from enum import Enum

# è®¾ç½® Windows ç»ˆç«¯ç¼–ç ä¸º UTF-8
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# é¢„å…ˆè®¾ç½® GENIE_DATA_DIR ç¯å¢ƒå˜é‡ï¼Œé˜²æ­¢ genie-tts åº“åœ¨å¯¼å…¥æ—¶è§¦å‘äº¤äº’å¼ä¸‹è½½æç¤º
# è¿™å¿…é¡»åœ¨å¯¼å…¥ä»»ä½•å¯èƒ½ä¾èµ– genie_tts çš„æ¨¡å—ä¹‹å‰è®¾ç½®
if not os.environ.get('GENIE_DATA_DIR'):
    # ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼ˆall_ready.py åœ¨ backend/ ç›®å½•ä¸‹ï¼‰
    _backend_dir = Path(__file__).parent  # backend/
    _default_genie_data = _backend_dir / 'data' / 'tts' / 'GenieData'
    os.environ['GENIE_DATA_DIR'] = str(_default_genie_data.resolve())

# =============================================================================
# å½©è‰²ç»ˆç«¯è¾“å‡º
# =============================================================================

class Color:
    """ç»ˆç«¯é¢œè‰²ä»£ç """
    RESET = '\033[0m'
    BOLD = '\033[1m'
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'


def print_header(text: str):
    """æ‰“å°æ ‡é¢˜"""
    print(f"\n{Color.BOLD}{Color.CYAN}{'=' * 60}{Color.RESET}")
    print(f"{Color.BOLD}{Color.CYAN}{text}{Color.RESET}")
    print(f"{Color.BOLD}{Color.CYAN}{'=' * 60}{Color.RESET}\n")


def print_success(text: str):
    """æ‰“å°æˆåŠŸä¿¡æ¯"""
    print(f"{Color.GREEN}âœ… {text}{Color.RESET}")


def print_error(text: str):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    print(f"{Color.RED}âŒ {text}{Color.RESET}")


def print_warning(text: str):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    print(f"{Color.YELLOW}âš ï¸  {text}{Color.RESET}")


def print_info(text: str):
    """æ‰“å°ä¿¡æ¯"""
    print(f"{Color.BLUE}â„¹ï¸  {text}{Color.RESET}")


def print_step(text: str):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"{Color.MAGENTA}â¤ {text}{Color.RESET}")


# =============================================================================
# æ¨¡å‹çŠ¶æ€æšä¸¾
# =============================================================================

class ModelStatus(Enum):
    """æ¨¡å‹çŠ¶æ€"""
    NOT_FOUND = "not_found"
    INCOMPLETE = "incomplete"
    INSTALLED = "installed"


# =============================================================================
# é…ç½®åŠ è½½å™¨
# =============================================================================

class ConfigLoader:
    """é…ç½®åŠ è½½å™¨ - ä» core_config.json è¯»å–é…ç½®"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.config_path = project_root / "backend" / "config" / "core_config.json"
        self._config_data: Optional[Dict[str, Any]] = None
    
    def load(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if self._config_data is not None:
            return self._config_data
        
        if not self.config_path.exists():
            print_error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_path}")
            sys.exit(1)
        
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self._config_data = json.load(f)
            print_success(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {self.config_path}")
            return self._config_data
        except Exception as e:
            print_error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
    
    def get_config(self, key: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šé…ç½®"""
        return self.load().get(key, {})
    
    def get_data_dir(self, model_type: str) -> Path:
        """è·å–æ¨¡å‹æ•°æ®ç›®å½•"""
        config = self.get_config(model_type)
        
        if model_type == "tts":
            data_dir = config.get("genie_data_dir", "backend/data/tts")
        else:  # asr
            data_dir = "backend/data/asr"
        
        return self._to_abs_path(data_dir)
    
    def get_model_dir(self, model_type: str) -> Path:
        """è·å–æ¨¡å‹ç›®å½•è·¯å¾„"""
        if model_type == "tts":
            return self.get_data_dir("tts") / "GenieData"
        
        # ASR æ¨¡å‹ç›®å½• - é»˜è®¤ä½¿ç”¨ funasr_nano
        return self.get_data_dir("asr") / "funasr_nano"
    
    def _to_abs_path(self, path: str) -> Path:
        """è½¬æ¢ä¸ºç»å¯¹è·¯å¾„"""
        return Path(path) if os.path.isabs(path) else self.project_root / path


# =============================================================================
# ç»Ÿä¸€æ¨¡å‹æ£€æµ‹å™¨
# =============================================================================

class ModelChecker:
    """ç»Ÿä¸€æ¨¡å‹æ£€æµ‹å™¨ - æ”¯æŒTTSå’ŒASR"""
    
    def __init__(self, config_loader: ConfigLoader):
        self.config_loader = config_loader
    
    def check(self, model_type: str) -> Tuple[ModelStatus, List[str]]:
        """
        æ£€æµ‹æ¨¡å‹çŠ¶æ€
        
        Args:
            model_type: 'tts' æˆ– 'asr'
        
        Returns:
            (çŠ¶æ€, ç¼ºå¤±é¡¹åˆ—è¡¨)
        """
        if model_type == "tts":
            return self._check_tts()
        elif model_type == "asr":
            return self._check_asr()
        else:
            raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}")
    
    def _check_tts(self) -> Tuple[ModelStatus, List[str]]:
        """æ£€æµ‹TTSæ¨¡å‹"""
        print_step("æ£€æµ‹ TTS æ¨¡å‹...")
        
        tts_config = self.config_loader.get_config("tts")
        genie_data_dir = self.config_loader.get_model_dir("tts")
        missing_items = []
        
        # æ£€æŸ¥ GenieData ç›®å½•
        if not genie_data_dir.exists():
            missing_items.append("GenieData ç›®å½•")
            print_warning(f"GenieData ç›®å½•ä¸å­˜åœ¨: {genie_data_dir}")
            return ModelStatus.NOT_FOUND, missing_items
        
        # æ£€æŸ¥æ ¸å¿ƒç»„ä»¶
        components = {
            "chinese-hubert-base": genie_data_dir / "chinese-hubert-base",
            "CharacterModels": genie_data_dir / "CharacterModels"
        }
        
        for name, path in components.items():
            if not path.exists():
                missing_items.append(f"{name} æ¨¡å‹")
                print_warning(f"{name} ä¸å­˜åœ¨: {path}")
        
        # æ£€æŸ¥æ´»è·ƒè§’è‰²
        if "CharacterModels" not in missing_items:
            active_char = tts_config.get("active_character", "feibi")
            char_dir = components["CharacterModels"] / "v2ProPlus" / active_char
            
            if not char_dir.exists():
                missing_items.append(f"è§’è‰²æ¨¡å‹ '{active_char}'")
                print_warning(f"è§’è‰²æ¨¡å‹ä¸å­˜åœ¨: {char_dir}")
            else:
                # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
                for file_name in ["tts_models", "prompt_wav.json"]:
                    if not (char_dir / file_name).exists():
                        missing_items.append(f"è§’è‰²æ–‡ä»¶ {file_name}")
                        print_warning(f"è§’è‰²æ–‡ä»¶ç¼ºå¤±: {char_dir / file_name}")
        
        # è¿”å›çŠ¶æ€
        if not missing_items:
            print_success("TTS æ¨¡å‹æ£€æµ‹å®Œæˆï¼Œæ‰€æœ‰ç»„ä»¶å·²å®‰è£…")
            return ModelStatus.INSTALLED, []
        
        status = ModelStatus.NOT_FOUND if "GenieData ç›®å½•" in missing_items else ModelStatus.INCOMPLETE
        print_warning(f"TTS æ¨¡å‹ä¸å®Œæ•´ï¼Œç¼ºå¤± {len(missing_items)} é¡¹")
        return status, missing_items
    
    def _check_asr(self) -> Tuple[ModelStatus, List[str]]:
        """æ£€æµ‹ASRæ¨¡å‹"""
        print_step("æ£€æµ‹ ASR æ¨¡å‹...")
        
        asr_config = self.config_loader.get_config("asr")
        engine = asr_config.get("engine", "dummy")
        
        # dummy å¼•æ“æ— éœ€æ¨¡å‹
        if engine == "dummy":
            print_info("ASR å¼•æ“é…ç½®ä¸º 'dummy' (æµ‹è¯•æ¨¡å¼)ï¼Œæ— éœ€æ¨¡å‹æ–‡ä»¶")
            return ModelStatus.INSTALLED, []
        
        # funasr å¼•æ“ä½¿ç”¨ ModelScope ç¼“å­˜
        if engine == "funasr":
            model_cache_dir = self.config_loader.get_data_dir("asr")
            return self._check_funasr_models(model_cache_dir)
        
        # å…¶ä»–å¼•æ“ï¼ˆfunasr_automodel ç­‰ï¼‰æ£€æŸ¥æ¨¡å‹ç›®å½•
        model_dir = self.config_loader.get_model_dir("asr")
        
        if not model_dir.exists():
            print_warning(f"ASR æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
            return ModelStatus.NOT_FOUND, [f"{engine} æ¨¡å‹ç›®å½•"]
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ¨¡å‹æ–‡ä»¶ (.onnx, .pt, model.py)
        model_files = list(model_dir.glob("*.onnx")) + list(model_dir.glob("*.pt")) + list(model_dir.glob("model.py"))
        
        if model_files:
            total_size_mb = sum(f.stat().st_size for f in model_files if f.is_file()) / (1024 * 1024)
            file_names = [f.name for f in model_files]
            print_success(f"ASR æ¨¡å‹å·²å­˜åœ¨: {model_dir}")
            print_info(f"  æ–‡ä»¶: {', '.join(file_names)} | æ€»å¤§å°: {total_size_mb:.2f} MB")
            return ModelStatus.INSTALLED, []
        else:
            print_warning(f"ASR æ¨¡å‹ç›®å½•å­˜åœ¨ä½†æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_dir}")
            return ModelStatus.NOT_FOUND, [f"{engine} æ¨¡å‹æ–‡ä»¶"]
    
    def _check_funasr_models(self, cache_dir: Path) -> Tuple[ModelStatus, List[str]]:
        """æ£€æµ‹ FunASR æ¨¡å‹ï¼ˆFunASR ç¼“å­˜ç»“æ„ï¼‰"""
        missing_items = []
        
        # æ£€æŸ¥ç¼“å­˜ç›®å½•
        if not cache_dir.exists():
            print_warning(f"FunASR æ¨¡å‹ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
            return ModelStatus.NOT_FOUND, ["FunASR æ¨¡å‹ç¼“å­˜ç›®å½•"]
        
        # FunASR ä½¿ç”¨ models ç›®å½•ç»“æ„ï¼Œè€Œé hub
        models_dir = cache_dir / "models"
        if not models_dir.exists():
            print_warning(f"FunASR models ç›®å½•ä¸å­˜åœ¨: {models_dir}")
            return ModelStatus.NOT_FOUND, ["FunASR models ç›®å½•"]
        
        # æ£€æŸ¥å¿…éœ€æ¨¡å‹
        required_models = {
            "VAD æ¨¡å‹": "iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
            "è¯­è¨€è¯†åˆ«æ¨¡å‹": "iic/SenseVoiceSmall",
        }
        
        for model_name, model_id in required_models.items():
            model_path = self._find_model_in_cache(models_dir, model_id)
            if model_path:
                print_success(f"{model_name}: âœ“ ({model_path})")
            else:
                missing_items.append(model_name)
                print_warning(f"{model_name}: âœ—")
        
        # æ£€æŸ¥å¯é€‰æ¨¡å‹ï¼ˆä»…æ˜¾ç¤ºçŠ¶æ€ï¼Œä¸å½±å“å®‰è£…åˆ¤æ–­ï¼‰
        optional_models = {
            "æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹": "iic/emotion2vec_plus_large",
            "è¯´è¯äººè¾¨åˆ«æ¨¡å‹": "iic/speech_campplus_sv_zh-cn_16k-common",
        }
        
        print("")
        print_info("å¯é€‰æ¨¡å‹çŠ¶æ€:")
        for model_name, model_id in optional_models.items():
            model_path = self._find_model_in_cache(models_dir, model_id)
            if model_path:
                print_success(f"  {model_name}: âœ“ ({model_path.name})")
            else:
                print_info(f"  {model_name}: âœ— (ä½¿ç”¨ --download-emotion æˆ– --download-speaker ä¸‹è½½)")
        
        if not missing_items:
            print_success("FunASR æ‰€æœ‰å¿…éœ€æ¨¡å‹å·²å®‰è£…")
            return ModelStatus.INSTALLED, []
        else:
            print_warning(f"FunASR æ¨¡å‹ä¸å®Œæ•´ï¼Œç¼ºå¤± {len(missing_items)} é¡¹")
            return ModelStatus.INCOMPLETE, missing_items
    
    def _find_model_in_cache(self, models_dir: Path, model_id: str) -> Optional[Path]:
        """åœ¨ç¼“å­˜ä¸­æŸ¥æ‰¾æ¨¡å‹"""
        # FunASR ä½¿ç”¨çš„ç›®å½•ç»“æ„: models/iic/SenseVoiceSmall
        parts = model_id.split("/")
        
        if len(parts) == 2:
            # æ ‡å‡†æ ¼å¼: iic/SenseVoiceSmall
            model_path = models_dir / parts[0] / parts[1]
            if model_path.exists():
                return model_path
        
        # ä¹Ÿå°è¯•æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„å‘½å
        for item in models_dir.rglob(parts[-1]):
            if item.is_dir():
                return item
        
        return None


# =============================================================================
# ç»Ÿä¸€æ¨¡å‹ä¸‹è½½å™¨
# =============================================================================

class ModelDownloader:
    """ç»Ÿä¸€æ¨¡å‹ä¸‹è½½å™¨ - æ”¯æŒTTSå’ŒASR"""
    
    # HuggingFace ä»“åº“é…ç½®
    REPO_CONFIG = {
        "tts": {
            "repo_id": "High-Logic/Genie",
            "patterns": "GenieData/*",
            "name": "Genie-TTS"
        },
        "asr": {
            "repo_id": "FunAudioLLM/Fun-ASR-Nano-2512",
            "patterns": "*",
            "name": "FunAudioLLM/Fun-ASR-Nano-2512",
            "size": "~2GB"
        }
    }
    
    def __init__(self, config_loader: ConfigLoader):
        self.config_loader = config_loader
        self._hf_available = self._check_huggingface_hub()
    
    def _check_huggingface_hub(self) -> bool:
        """æ£€æŸ¥ huggingface_hub ä¾èµ–"""
        try:
            import huggingface_hub
            print_success(f"huggingface_hub å·²å®‰è£… (ç‰ˆæœ¬: {huggingface_hub.__version__})")
            return True
        except ImportError:
            print_warning("huggingface_hub æœªå®‰è£…ï¼ˆä¸‹è½½æ¨¡å‹æ—¶éœ€è¦ï¼‰")
            print_info("å®‰è£…å‘½ä»¤: pip install huggingface-hub")
            return False
    
    def download(self, model_type: str, force: bool = False) -> bool:
        """
        ä¸‹è½½æ¨¡å‹
        
        Args:
            model_type: 'tts' æˆ– 'asr'
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if model_type == "tts":
            return self._download_tts(force)
        elif model_type == "asr":
            return self._download_asr(force)
        else:
            print_error(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}")
            return False
    
    def _download_tts(self, force: bool) -> bool:
        """ä¸‹è½½TTSæ¨¡å‹"""
        print_header("ä¸‹è½½ TTS æ¨¡å‹")
        
        if not self._hf_available:
            print_error("huggingface_hub æœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹")
            print_info("å®‰è£…å‘½ä»¤: pip install huggingface-hub")
            return False
        
        from huggingface_hub import snapshot_download
        
        data_dir = self.config_loader.get_data_dir("tts")
        genie_data_dir = self.config_loader.get_model_dir("tts")
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if genie_data_dir.exists() and not force:
            hubert_dir = genie_data_dir / "chinese-hubert-base"
            if hubert_dir.exists():
                print_info("TTS æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½ï¼ˆä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼‰")
                return True
        
        config = self.REPO_CONFIG["tts"]
        print_info(f"ä» HuggingFace ä¸‹è½½ {config['name']} æ¨¡å‹...")
        print_info(f"ä»“åº“: {config['repo_id']}")
        print_info(f"ç›®æ ‡ç›®å½•: {data_dir}")
        print_warning("é¦–æ¬¡ä¸‹è½½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        try:
            data_dir.mkdir(parents=True, exist_ok=True)
            
            print_step("æ­£åœ¨ä¸‹è½½ GenieData...")
            snapshot_download(
                repo_id=config["repo_id"],
                repo_type="model",
                allow_patterns=config["patterns"],
                local_dir=str(data_dir),
                local_dir_use_symlinks=False,
                resume_download=True,
            )
            
            print_success(f"âœ… {config['name']} æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
            
            # ä¸‹è½½é»˜è®¤è§’è‰²
            self._download_character()
            
            return True
            
        except Exception as e:
            print_error(f"ä¸‹è½½å¤±è´¥: {e}")
            self._show_manual_download_help("tts")
            return False
    
    def _download_asr(self, force: bool) -> bool:
        """ä¸‹è½½ASRæ¨¡å‹"""
        print_header("ä¸‹è½½ ASR æ¨¡å‹")
        
        asr_config = self.config_loader.get_config("asr")
        engine = asr_config.get("engine", "dummy")
        
        if engine == "dummy":
            print_info("ASR å¼•æ“é…ç½®ä¸º 'dummy'ï¼Œæ— éœ€ä¸‹è½½æ¨¡å‹")
            return True
        
        # funasr å¼•æ“ä½¿ç”¨ ModelScope ä¸‹è½½
        if engine == "funasr":
            cache_dir = self.config_loader.get_data_dir("asr")
            return self._download_funasr_models(cache_dir, force)
        
        
        model_dir = self.config_loader.get_model_dir("asr")
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if not force and model_dir.exists():
            # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æ–‡ä»¶
            model_files = list(model_dir.glob("*.onnx")) + list(model_dir.glob("*.pt")) + list(model_dir.glob("model.py"))
            if model_files:
                print_info("ASR æ¨¡å‹å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½ï¼ˆä½¿ç”¨ --force å¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼‰")
                return True
        
        # æ˜¾ç¤ºä¸‹è½½ä¿¡æ¯å¹¶è¯¢é—®ç”¨æˆ·
        if not self._confirm_asr_download(model_dir):
            return False
        
        # æ‰§è¡Œä¸‹è½½
        return self._execute_asr_download(model_dir)
    
    def _confirm_asr_download(self, model_dir: Path) -> bool:
        """ç¡®è®¤ASRæ¨¡å‹ä¸‹è½½"""
        config = self.REPO_CONFIG["asr"]
        
        print_info("")
        print_info("æ£€æµ‹åˆ° ASR æ¨¡å‹å°šæœªå®‰è£…ã€‚")
        print_info("")
        print_info("ğŸ“¦ æ¨¡å‹ä¿¡æ¯ï¼š")
        print_info(f"  åç§°: {config['name']}")
        print_info(f"  æ¥æº: HuggingFace ({config['repo_id']})")
        print_info(f"  ç›®æ ‡ç›®å½•: {model_dir}")
        print_info(f"  é¢„è®¡å¤§å°: {config['size']}")
        print_info("  ä¸‹è½½æ—¶é—´: 5-15åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œé€Ÿåº¦ï¼‰")
        print_info("")
        
        try:
            response = input("æ˜¯å¦ç«‹å³ä» HuggingFace ä¸‹è½½æ­¤æ¨¡å‹ï¼Ÿ(y/N): ").strip().lower()
            return response in ['y', 'yes', 'æ˜¯']
        except (EOFError, KeyboardInterrupt):
            print_info("\nå·²å–æ¶ˆä¸‹è½½")
            return False
    
    def _execute_asr_download(self, model_dir: Path) -> bool:
        """æ‰§è¡ŒASRæ¨¡å‹ä¸‹è½½"""
        if not self._hf_available:
            print_error("huggingface_hub æœªå®‰è£…ï¼Œæ— æ³•ä¸‹è½½æ¨¡å‹")
            print_info("å®‰è£…å‘½ä»¤: pip install huggingface-hub")
            return False
        
        from huggingface_hub import snapshot_download
        
        config = self.REPO_CONFIG["asr"]
        print_info("")
        print_warning("â³ å¼€å§‹ä¸‹è½½ï¼Œè¯·ç¨å€™...")
        print_info("")
        
        model_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            print_step("æ­£åœ¨è¿æ¥ HuggingFace...")
            
            download_dir = snapshot_download(
                repo_id=config["repo_id"],
                local_dir=str(model_dir),
                local_dir_use_symlinks=False,
                resume_download=True,
                allow_patterns=config["patterns"],
            )
            
            print_success(f"æ¨¡å‹ä¸‹è½½å®Œæˆ: {download_dir}")
            
            # åˆ›å»ºå…ƒæ•°æ®
            self._create_metadata(model_dir, "asr")
            
            # æ˜¾ç¤ºä¸‹è½½ç»“æœ
            self._show_download_summary(model_dir)
            
            print_success("")
            print_success("ğŸ‰ ASR æ¨¡å‹å®‰è£…å®Œæˆï¼")
            print_info("")
            print_info("ä¸‹ä¸€æ­¥ï¼š")
            print_info("  1. åœ¨ backend/config/core_config.json ä¸­è®¾ç½®:")
            print_info("     - asr.enabled = true")
            print_info("     - asr.engine = \"funasr_automodel\"")
            print_info("     - asr.model_dir = æ¨¡å‹ç›®å½•è·¯å¾„")
            print_info("  2. ç¡®ä¿å·²å®‰è£…: pip install funasr")
            
            return True
            
        except Exception as e:
            print_error(f"ä¸‹è½½å¤±è´¥: {e}")
            self._show_download_error_help(str(e), model_dir)
            return False
    
    def _download_funasr_models(self, cache_dir: Path, force: bool) -> bool:
        """ä¸‹è½½ FunASR æ¨¡å‹åˆ° ModelScope ç¼“å­˜ï¼ˆé€ä¸ªè¯¢é—®ï¼‰"""
        print_info("å‡†å¤‡æ£€æŸ¥å’Œä¸‹è½½ FunASR æ¨¡å‹...")
        
        # è®¾ç½® ModelScope ç¼“å­˜ç›®å½•
        cache_dir.mkdir(parents=True, exist_ok=True)
        os.environ["MODELSCOPE_CACHE"] = str(cache_dir)
        
        print_info(f"æ¨¡å‹ç¼“å­˜ç›®å½•: {cache_dir}")
        print_info("")
        print_info("ğŸ’¡ æç¤º:")
        print_info("  - å°†é€ä¸ªæ£€æŸ¥å¿…éœ€æ¨¡å‹çš„å®‰è£…çŠ¶æ€")
        print_info("  - å¦‚æœæ¨¡å‹ç¼ºå¤±ï¼Œä¼šè¯¢é—®æ‚¨æ˜¯å¦ä¸‹è½½")
        print_info("  - å¯é€‰æ¨¡å‹è¯·ä½¿ç”¨ --download-emotion æˆ– --download-speaker ä¸‹è½½")
        
        # ç›´æ¥æ‰§è¡Œé€ä¸ªæ£€æŸ¥å’Œä¸‹è½½
        return self._execute_funasr_download(cache_dir)
    
    def _execute_funasr_download(self, cache_dir: Path) -> bool:
        """æ‰§è¡Œ FunASR æ¨¡å‹ä¸‹è½½ï¼ˆé€ä¸ªè¯¢é—®ï¼‰"""
        print_info("")
        print_info("å¼€å§‹æ£€æŸ¥å’Œä¸‹è½½ FunASR æ¨¡å‹...")
        print_info("")
        
        try:
            # æ£€æŸ¥ FunASR æ˜¯å¦å·²å®‰è£…
            try:
                from funasr import AutoModel
                print_success("âœ“ FunASR å·²å®‰è£…")
            except ImportError:
                print_error("âŒ FunASR æœªå®‰è£…")
                print_info("è¯·å…ˆå®‰è£…: pip install funasr")
                return False
            
            print_info("")
            
            # å®šä¹‰å¿…éœ€æ¨¡å‹åŠå…¶ä¿¡æ¯
            models_info = [
                {
                    "name": "VAD æ¨¡å‹",
                    "id": "fsmn-vad",
                    "description": "è¯­éŸ³ç«¯ç‚¹æ£€æµ‹ï¼Œè¯†åˆ«éŸ³é¢‘ä¸­çš„æœ‰æ•ˆè¯­éŸ³æ®µ",
                    "size": "~4MB",
                    "path": cache_dir / "models" / "iic" / "speech_fsmn_vad_zh-cn-16k-common-pytorch"
                },
                {
                    "name": "è¯­è¨€è¯†åˆ«æ¨¡å‹",
                    "id": "iic/SenseVoiceSmall",
                    "description": "å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«å’Œè½¬å†™ï¼ˆæ”¯æŒä¸­/è‹±/æ—¥/éŸ©/ç²¤è¯­ï¼‰",
                    "size": "~900MB",
                    "path": cache_dir / "models" / "iic" / "SenseVoiceSmall"
                },
            ]
            
            downloaded_models = []
            skipped_models = []
            failed_models = []
            
            # é€ä¸ªæ£€æŸ¥å’Œä¸‹è½½æ¨¡å‹
            for model_info in models_info:
                model_name = model_info["name"]
                model_id = model_info["id"]
                model_path = model_info["path"]
                
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
                if model_path.exists():
                    print_success(f"âœ“ {model_name} å·²å®‰è£…")
                    downloaded_models.append(model_name)
                    continue
                
                # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
                print_info("â”€" * 60)
                print_warning(f"âš ï¸  {model_name} æœªå®‰è£…")
                print_info(f"  æ¨¡å‹ ID: {model_id}")
                print_info(f"  åŠŸèƒ½: {model_info['description']}")
                print_info(f"  å¤§å°: {model_info['size']}")
                print_info("")
                
                # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä¸‹è½½
                try:
                    response = input(f"æ˜¯å¦ä¸‹è½½ {model_name}ï¼Ÿ(y/N): ").strip().lower()
                    if response not in ['y', 'yes', 'æ˜¯']:
                        print_info(f"å·²è·³è¿‡ {model_name}")
                        skipped_models.append(model_name)
                        print_info("")
                        continue
                except (EOFError, KeyboardInterrupt):
                    print_info(f"\nå·²è·³è¿‡ {model_name}")
                    skipped_models.append(model_name)
                    print_info("")
                    continue
                
                # ä¸‹è½½æ¨¡å‹
                print_step(f"æ­£åœ¨ä¸‹è½½ {model_name}...")
                try:
                    model = AutoModel(model=model_id, device="cpu")
                    print_success(f"âœ… {model_name} ä¸‹è½½å®Œæˆ")
                    downloaded_models.append(model_name)
                    
                    # é‡Šæ”¾æ¨¡å‹å†…å­˜
                    del model
                    
                except Exception as e:
                    print_error(f"âŒ {model_name} ä¸‹è½½å¤±è´¥: {e}")
                    failed_models.append((model_name, str(e)))
                
                print_info("")
            
            # æ˜¾ç¤ºä¸‹è½½æ€»ç»“
            print_info("â”€" * 60)
            print_header("ä¸‹è½½æ€»ç»“")
            
            if downloaded_models:
                print_success(f"âœ… å·²å®‰è£…çš„æ¨¡å‹ ({len(downloaded_models)}):")
                for model_name in downloaded_models:
                    print_success(f"  âœ“ {model_name}")
                print_info("")
            
            if skipped_models:
                print_warning(f"â­ï¸  è·³è¿‡çš„æ¨¡å‹ ({len(skipped_models)}):")
                for model_name in skipped_models:
                    print_warning(f"  - {model_name}")
                print_info("")
            
            if failed_models:
                print_error(f"âŒ ä¸‹è½½å¤±è´¥çš„æ¨¡å‹ ({len(failed_models)}):")
                for model_name, error in failed_models:
                    print_error(f"  âœ— {model_name}: {error}")
                print_info("")
            
            # æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰å¿…éœ€çš„æ¨¡å‹
            required_models = ["VAD æ¨¡å‹", "è¯­è¨€è¯†åˆ«æ¨¡å‹"]
            installed_required = [m for m in required_models if m in downloaded_models]
            
            if len(installed_required) == len(required_models):
                print_success("ğŸ‰ æ‰€æœ‰å¿…éœ€æ¨¡å‹å·²å®‰è£…ï¼")
                print_info("")
                
                # è¯¢é—®æ˜¯å¦ä¸‹è½½å¯é€‰æ¨¡å‹
                optional_downloaded = self._ask_download_optional_models(cache_dir)
                
                print_info("ä¸‹ä¸€æ­¥ï¼š")
                print_info("  1. åœ¨ backend/config/core_config.json ä¸­è®¾ç½®:")
                print_info("     - asr.enabled = true")
                print_info("     - asr.engine = \"funasr\"")
                print_info(f"     - asr.model_cache_dir = \"{cache_dir}\"")
                if optional_downloaded:
                    print_info("     - ser_enabled = true  (å¦‚æœä¸‹è½½äº†æƒ…æ„Ÿè¯†åˆ«)")
                    print_info("     - speaker_enabled = true  (å¦‚æœä¸‹è½½äº†è¯´è¯äººè¾¨åˆ«)")
                print_info("  2. è¿è¡Œæµ‹è¯•: python backend/test/test_funasr.py")
                return True
            else:
                missing_required = [m for m in required_models if m not in downloaded_models]
                print_warning("âš ï¸  éƒ¨åˆ†å¿…éœ€æ¨¡å‹æœªå®‰è£…")
                print_warning(f"ç¼ºå¤±: {', '.join(missing_required)}")
                print_info("")
                print_info("è¯·é‡æ–°è¿è¡Œ: python backend/all_ready.py --asr-only")
                return False
            
        except Exception as e:
            print_error(f"ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return False
    

    
    def _create_metadata(self, model_dir: Path, model_type: str):
        """åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶"""
        if model_type == "asr":
            metadata = {
                "model_name": "Fun-ASR-Nano-2512",
                "version": "2512",
                "source": "HuggingFace",
                "repo_id": self.REPO_CONFIG["asr"]["repo_id"],
                "download_date": time.strftime("%Y-%m-%d"),
                "engine": "funasr_automodel",
                "format": "PyTorch/ONNX"
            }
            
            metadata_file = model_dir / "metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            print_success("âœ… å…ƒæ•°æ®æ–‡ä»¶å·²åˆ›å»º")
    
    def _show_download_summary(self, model_dir: Path):
        """æ˜¾ç¤ºä¸‹è½½æ‘˜è¦"""
        print_info("")
        print_info("ä¸‹è½½çš„æ–‡ä»¶:")
        for file in sorted(model_dir.iterdir()):
            if file.is_file():
                size_mb = file.stat().st_size / (1024 * 1024)
                print_info(f"  - {file.name} ({size_mb:.2f} MB)")
    
    def _download_character(self):
        """ä¸‹è½½é»˜è®¤è§’è‰²æ¨¡å‹"""
        print_step("æ£€æŸ¥é»˜è®¤è§’è‰²æ¨¡å‹...")
        
        try:
            import genie_tts as genie
            
            tts_config = self.config_loader.get_config("tts")
            active_character = tts_config.get("active_character", "feibi")
            
            genie_data_dir = self.config_loader.get_model_dir("tts")
            os.environ['GENIE_DATA_DIR'] = str(genie_data_dir.resolve())
            
            # æ£€æŸ¥è§’è‰²æ˜¯å¦å·²å­˜åœ¨
            character_dir = genie_data_dir / "CharacterModels" / "v2ProPlus" / active_character
            
            if character_dir.exists():
                print_info(f"è§’è‰² '{active_character}' å·²å­˜åœ¨")
                return
            
            print_info(f"æ­£åœ¨ä¸‹è½½é»˜è®¤è§’è‰² '{active_character}'...")
            genie.load_predefined_character(active_character)
            print_success(f"âœ… è§’è‰² '{active_character}' ä¸‹è½½å®Œæˆï¼")
            
        except ImportError:
            print_warning("genie_tts æœªå®‰è£…ï¼Œè·³è¿‡è§’è‰²ä¸‹è½½")
        except Exception as e:
            print_warning(f"ä¸‹è½½è§’è‰²å¤±è´¥: {e}")
            print_info("å¯ä»¥ç¨åæ‰‹åŠ¨ä¸‹è½½æˆ–åœ¨é¦–æ¬¡ä½¿ç”¨TTSæ—¶è‡ªåŠ¨ä¸‹è½½")
    
    def _show_manual_download_help(self, model_type: str):
        """æ˜¾ç¤ºæ‰‹åŠ¨ä¸‹è½½å¸®åŠ©"""
        print_info("")
        print_info("ğŸ’¡ æ‰‹åŠ¨ä¸‹è½½æ–¹æ³•ï¼š")
        
        config = self.REPO_CONFIG[model_type]
        repo_url = f"https://huggingface.co/{config['repo_id']}"
        
        print_info(f"  1. è®¿é—®: {repo_url}")
        print_info("  2. ä¸‹è½½æ‰€éœ€æ–‡ä»¶")
        print_info(f"  3. æ”¾ç½®åˆ°ç›¸åº”ç›®å½•")
    
    def _show_download_error_help(self, error_msg: str, model_dir: Path):
        """æ˜¾ç¤ºä¸‹è½½é”™è¯¯å¸®åŠ©"""
        print_info("")
        
        if any(kw in error_msg.lower() for kw in ["internet", "connection", "network"]):
            print_warning("ğŸŒ ç½‘ç»œè¿æ¥é—®é¢˜")
            print_info("")
            print_info("ğŸ”§ è§£å†³æ–¹æ¡ˆï¼š")
            print_info("")
            print_info("1ï¸âƒ£ è®¾ç½® HuggingFace é•œåƒç«™ï¼ˆå›½å†…ç”¨æˆ·æ¨èï¼‰ï¼š")
            print_info("   # Windows PowerShell")
            print_info("   $env:HF_ENDPOINT = 'https://hf-mirror.com'")
            print_info("   python all_ready.py --asr-only")
            print_info("")
            print_info("2ï¸âƒ£ è®¾ç½®ä»£ç†ï¼ˆå¦‚æœæœ‰ï¼‰ï¼š")
            print_info("   $env:HTTP_PROXY = 'http://127.0.0.1:7890'")
            print_info("   $env:HTTPS_PROXY = 'http://127.0.0.1:7890'")
        
        print_info("")
        print_info("ğŸ’¡ æ‰‹åŠ¨ä¸‹è½½ï¼š")
        print_info(f"  è®¿é—®: https://huggingface.co/{self.REPO_CONFIG['asr']['repo_id']}")
        print_info(f"  æ”¾ç½®åˆ°: {model_dir}")


# =============================================================================
# ä¾èµ–æ£€æŸ¥å™¨
# =============================================================================

class DependencyChecker:
    """ä¾èµ–æ£€æŸ¥å™¨"""
    
    # å¿…éœ€åŒ…ï¼š(importå, æ˜¾ç¤ºå, ç‰ˆæœ¬è¦æ±‚)
    REQUIRED_PACKAGES = [
        ('openai', 'openai', '>=1.60.0'),
        ('pydantic', 'pydantic', '>=2.10.0'),
        ('pydantic_settings', 'pydantic-settings', '>=2.7.0'),
        ('numpy', 'numpy', '>=1.26.0'),
        ('aiohttp', 'aiohttp', '>=3.9.0'),
        ('fastapi', 'fastapi', '>=0.110.0'),
        ('uvicorn', 'uvicorn', '>=0.28.0'),
    ]
    
    # å¯é€‰åŒ…ï¼š(importå, æ˜¾ç¤ºå, æè¿°)
    OPTIONAL_PACKAGES = [
        ('genie_tts', 'genie-tts', 'TTSåŠŸèƒ½'),
        ('funasr', 'funasr', 'ASRåŠŸèƒ½'),
        ('huggingface_hub', 'huggingface-hub', 'æ¨¡å‹ä¸‹è½½'),
    ]
    
    @staticmethod
    def check_python_version() -> bool:
        """æ£€æŸ¥Pythonç‰ˆæœ¬"""
        print_step("æ£€æŸ¥ Python ç‰ˆæœ¬...")
        
        version = sys.version_info
        version_str = f"{version.major}.{version.minor}.{version.micro}"
        
        if version.major == 3 and version.minor >= 8:
            print_success(f"Python ç‰ˆæœ¬: {version_str} âœ“")
            return True
        else:
            print_error(f"Python ç‰ˆæœ¬è¿‡ä½: {version_str}ï¼Œéœ€è¦ Python 3.8+")
            return False
    
    @classmethod
    def check_packages(cls) -> Tuple[Dict[str, bool], Dict[str, bool]]:
        """æ£€æŸ¥æ‰€æœ‰åŒ…"""
        print_step("æ£€æŸ¥ Python åŒ…...")
        
        required_results = {}
        optional_results = {}
        
        # æ£€æŸ¥å¿…éœ€åŒ…
        for import_name, display_name, version_req in cls.REQUIRED_PACKAGES:
            try:
                __import__(import_name)
                required_results[display_name] = True
                print_success(f"{display_name} {version_req} âœ“")
            except ImportError:
                required_results[display_name] = False
                print_warning(f"{display_name} {version_req} âœ—")
        
        # æ£€æŸ¥å¯é€‰åŒ…
        for import_name, display_name, description in cls.OPTIONAL_PACKAGES:
            try:
                __import__(import_name)
                optional_results[display_name] = True
                print_success(f"{display_name} ({description}) âœ“")
            except ImportError:
                optional_results[display_name] = False
                print_info(f"{display_name} ({description}) âœ—")
        
        return required_results, optional_results


# =============================================================================
# ä¸»ç¨‹åº
# =============================================================================

class AllReadyManager:
    """ä¸»ç®¡ç†å™¨"""
    
    def __init__(self, args: argparse.Namespace):
        self.args = args
        # all_ready.py åœ¨ backend/ ç›®å½•ä¸‹ï¼Œéœ€è¦è·å–é¡¹ç›®æ ¹ç›®å½•
        self.project_root = Path(__file__).parent.parent.resolve()  # ä» backend/ å›åˆ°é¡¹ç›®æ ¹ç›®å½•
        self.config_loader = ConfigLoader(self.project_root)
        self.model_checker = ModelChecker(self.config_loader)
        self.downloader = ModelDownloader(self.config_loader)
    
    def run(self) -> int:
        """
        è¿è¡Œä¸»æµç¨‹
        
        Returns:
            é€€å‡ºç  (0=æˆåŠŸ, 1=å¤±è´¥)
        """
        print_header("çµä¾æ™ºèƒ½ä½“ç³»ç»Ÿ - æ¨¡å‹ä¸æ•°æ®å®‰è£…å·¥å…·")
        
        print_info(f"é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        
        # å¤„ç†å¯é€‰æ¨¡å‹ä¸‹è½½
        if self.args.download_emotion or self.args.download_speaker:
            return self._download_optional_models()
        
        print_info(f"è¿è¡Œæ¨¡å¼: {'ä»…æ£€æµ‹' if self.args.check_only else 'æ£€æµ‹å¹¶å®‰è£…'}")
        
        if self.args.force:
            print_warning("å¼ºåˆ¶é‡æ–°å®‰è£…æ¨¡å¼")
        
        print("")
        
        # 1. æ£€æŸ¥ä¾èµ–
        if not self._check_dependencies():
            return 1
        
        # 2. æ£€æŸ¥æ¨¡å‹çŠ¶æ€
        needs_download = self._check_models()
        
        # 3. å¦‚æœä»…æ£€æµ‹æ¨¡å¼ï¼Œç»“æŸ
        if self.args.check_only:
            print_header("æ£€æµ‹å®Œæˆ")
            if needs_download:
                print_info("ä½¿ç”¨ python all_ready.py æ‰§è¡Œå®‰è£…")
            return 0
        
        # 4. ä¸‹è½½æ¨¡å‹
        if needs_download or self.args.force:
            if not self._download_models():
                return 1
        
        # 5. æ£€æŸ¥å¹¶è¯¢é—®å¯é€‰æ¨¡å‹ï¼ˆå³ä½¿å¿…éœ€æ¨¡å‹å·²å®‰è£…ï¼‰
        if not self.args.tts_only:
            asr_config = self.config_loader.get_config("asr")
            engine = asr_config.get("engine", "dummy")
            if engine == "funasr":
                cache_dir = self.config_loader.get_data_dir("asr")
                self._ask_download_optional_models(cache_dir)
        
        # 6. æœ€ç»ˆéªŒè¯
        print_header("æœ€ç»ˆéªŒè¯")
        self._check_models()
        
        print_header("å®‰è£…å®Œæˆ")
        print_success("æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®å·²å‡†å¤‡å°±ç»ªï¼")
        print_info("å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨æœåŠ¡ï¼š")
        print_info("  - TTSæœåŠ¡: python backend/genie_server.py")
        print_info("  - ä¸»æœåŠ¡: python backend/main.py")
        
        return 0
    
    def _check_dependencies(self) -> bool:
        """æ£€æŸ¥ä¾èµ–"""
        print_header("æ­¥éª¤ 1: æ£€æŸ¥ç¯å¢ƒä¾èµ–")
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        if not DependencyChecker.check_python_version():
            return False
        
        print("")
        
        # æ£€æŸ¥åŒ…
        required_results, optional_results = DependencyChecker.check_packages()
        missing_required = [pkg for pkg, installed in required_results.items() if not installed]
        
        if missing_required:
            print_error(f"ç¼ºå°‘å¿…éœ€çš„åŒ…: {', '.join(missing_required)}")
            print_info("å®‰è£…å‘½ä»¤: pip install -r backend/requirements.txt")
            return False
        
        missing_optional = [pkg for pkg, installed in optional_results.items() if not installed]
        if missing_optional:
            print_info(f"å¯é€‰åŒ…æœªå®‰è£…: {', '.join(missing_optional)}")
            print_info("æŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        
        return True
    
    def _check_models(self) -> bool:
        """
        æ£€æŸ¥æ¨¡å‹çŠ¶æ€
        
        Returns:
            æ˜¯å¦éœ€è¦ä¸‹è½½
        """
        print_header("æ­¥éª¤ 2: æ£€æŸ¥æ¨¡å‹çŠ¶æ€")
        
        needs_download = False
        
        # æ£€æŸ¥TTS
        if not self.args.asr_only:
            tts_status, tts_missing = self.model_checker.check("tts")
            
            if tts_status != ModelStatus.INSTALLED:
                needs_download = True
                print_warning(f"TTS æ¨¡å‹çŠ¶æ€: {tts_status.value}")
                if tts_missing:
                    print_warning(f"ç¼ºå¤±é¡¹: {', '.join(tts_missing)}")
            else:
                print_success("TTS æ¨¡å‹: å·²å®‰è£… âœ“")
        
        print("")
        
        # æ£€æŸ¥ASR
        if not self.args.tts_only:
            asr_status, asr_missing = self.model_checker.check("asr")
            
            if asr_status != ModelStatus.INSTALLED:
                needs_download = True
                print_warning(f"ASR æ¨¡å‹çŠ¶æ€: {asr_status.value}")
                if asr_missing:
                    print_warning(f"ç¼ºå¤±é¡¹: {', '.join(asr_missing)}")
            else:
                print_success("ASR æ¨¡å‹: å·²å®‰è£… âœ“")
        
        return needs_download
    
    def _download_models(self) -> bool:
        """ä¸‹è½½æ¨¡å‹"""
        print_header("æ­¥éª¤ 3: ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹")
        
        success = True
        
        # ä¸‹è½½TTS
        if not self.args.asr_only:
            tts_status, _ = self.model_checker.check("tts")
            
            if tts_status != ModelStatus.INSTALLED or self.args.force:
                if not self.downloader.download("tts", force=self.args.force):
                    success = False
        
        print("")
        
        # ä¸‹è½½ASR
        if not self.args.tts_only:
            asr_status, _ = self.model_checker.check("asr")
            
            if asr_status != ModelStatus.INSTALLED or self.args.force:
                if not self.downloader.download("asr", force=self.args.force):
                    success = False
        
        return success
    
    def _ask_download_optional_models(self, cache_dir: Path) -> bool:
        """
        è¯¢é—®ç”¨æˆ·æ˜¯å¦ä¸‹è½½å¯é€‰æ¨¡å‹
        
        Returns:
            æ˜¯å¦ä¸‹è½½äº†ä»»ä½•å¯é€‰æ¨¡å‹
        """
        try:
            from funasr import AutoModel
        except ImportError:
            return False
        
        # è®¾ç½® ModelScope ç¼“å­˜ç›®å½•ï¼ˆé‡è¦ï¼ï¼‰
        os.environ["MODELSCOPE_CACHE"] = str(cache_dir)
        
        print_info("")
        print_info("â”€" * 60)
        print_header("å¯é€‰æ¨¡å‹æ£€æŸ¥")
        
        # å®šä¹‰å¯é€‰æ¨¡å‹
        optional_models = [
            {
                "name": "æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹",
                "id": "emotion2vec_plus_large",
                "description": "è¯†åˆ«è¯­éŸ³ä¸­çš„æƒ…æ„Ÿå€¾å‘ï¼ˆå¼€å¿ƒ/æ„¤æ€’/ä¸­æ€§/æ‚²ä¼¤ç­‰ï¼‰",
                "size": "~1.8GB",
                "path": cache_dir / "models" / "iic" / "emotion2vec_plus_large",
                "config_key": "ser_enabled"
            },
            {
                "name": "è¯´è¯äººè¾¨åˆ«æ¨¡å‹",
                "id": "iic/speech_campplus_sv_zh-cn_16k-common",
                "description": "åŒºåˆ†éŸ³é¢‘ä¸­çš„ä¸åŒè¯´è¯äººå¹¶æ ‡æ³¨å½’å±",
                "size": "~200MB",
                "path": cache_dir / "models" / "iic" / "speech_campplus_sv_zh-cn_16k-common",
                "config_key": "speaker_enabled"
            }
        ]
        
        downloaded_any = False
        
        for model_info in optional_models:
            model_name = model_info["name"]
            model_id = model_info["id"]
            model_path = model_info["path"]
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
            if model_path.exists():
                print_success(f"âœ“ {model_name} å·²å®‰è£…")
                continue
            
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            print_info("")
            print_warning(f"âš ï¸  {model_name} æœªå®‰è£…")
            print_info(f"  æ¨¡å‹ ID: {model_id}")
            print_info(f"  åŠŸèƒ½: {model_info['description']}")
            print_info(f"  å¤§å°: {model_info['size']}")
            
            if model_info['size'].startswith('~1.8GB'):
                print_warning(f"  âš ï¸  è¯¥æ¨¡å‹è¾ƒå¤§ï¼Œä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
            
            print_info("")
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä¸‹è½½
            try:
                response = input(f"æ˜¯å¦ä¸‹è½½ {model_name}ï¼Ÿ(y/N): ").strip().lower()
                if response not in ['y', 'yes', 'æ˜¯']:
                    print_info(f"å·²è·³è¿‡ {model_name}")
                    continue
            except (EOFError, KeyboardInterrupt):
                print_info(f"\nå·²è·³è¿‡ {model_name}")
                continue
            
            # ä¸‹è½½æ¨¡å‹
            print_step(f"æ­£åœ¨ä¸‹è½½ {model_name}...")
            try:
                model = AutoModel(model=model_id, device="cpu")
                print_success(f"âœ… {model_name} ä¸‹è½½å®Œæˆ")
                downloaded_any = True
                del model
            except Exception as e:
                print_error(f"âŒ {model_name} ä¸‹è½½å¤±è´¥: {e}")
        
        print_info("")
        return downloaded_any
    
    def _download_optional_models(self) -> int:
        """ä¸‹è½½å¯é€‰çš„ FunASR æ¨¡å‹"""
        print_header("FunASR å¯é€‰æ¨¡å‹ä¸‹è½½")
        
        # è·å– ASR ç¼“å­˜ç›®å½•
        asr_cache_dir = self.config_loader.get_data_dir("asr")
        os.environ["MODELSCOPE_CACHE"] = str(asr_cache_dir)
        
        print_info(f"æ¨¡å‹ç¼“å­˜ç›®å½•: {asr_cache_dir}")
        print("")
        
        # æ£€æŸ¥ FunASR æ˜¯å¦å·²å®‰è£…
        try:
            from funasr import AutoModel
            print_success("âœ“ FunASR å·²å®‰è£…")
        except ImportError:
            print_error("âŒ FunASR æœªå®‰è£…")
            print_info("è¯·å…ˆå®‰è£…: pip install funasr")
            return 1
        
        print("")
        
        # å®šä¹‰å¯é€‰æ¨¡å‹ä¿¡æ¯
        optional_models = []
        
        if self.args.download_emotion:
            optional_models.append({
                "name": "æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹",
                "id": "emotion2vec_plus_large",
                "description": "è¯†åˆ«è¯­éŸ³ä¸­çš„æƒ…æ„Ÿå€¾å‘ï¼ˆå¼€å¿ƒ/æ„¤æ€’/ä¸­æ€§/æ‚²ä¼¤ç­‰ï¼‰",
                "size": "~1.8GB",
                "path": asr_cache_dir / "models" / "iic" / "emotion2vec_plus_large",
                "config_key": "ser_enabled"
            })
        
        if self.args.download_speaker:
            optional_models.append({
                "name": "è¯´è¯äººè¾¨åˆ«æ¨¡å‹",
                "id": "iic/speech_campplus_sv_zh-cn_16k-common",
                "description": "åŒºåˆ†éŸ³é¢‘ä¸­çš„ä¸åŒè¯´è¯äººå¹¶æ ‡æ³¨å½’å±",
                "size": "~200MB",
                "path": asr_cache_dir / "models" / "iic" / "speech_campplus_sv_zh-cn_16k-common",
                "config_key": "speaker_enabled"
            })
        
        if not optional_models:
            print_warning("æœªæŒ‡å®šè¦ä¸‹è½½çš„å¯é€‰æ¨¡å‹")
            print_info("ä½¿ç”¨æ–¹æ³•:")
            print_info("  --download-emotion  ä¸‹è½½æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹")
            print_info("  --download-speaker  ä¸‹è½½è¯´è¯äººè¾¨åˆ«æ¨¡å‹")
            return 0
        
        downloaded_models = []
        skipped_models = []
        failed_models = []
        
        # é€ä¸ªå¤„ç†æ¨¡å‹
        for model_info in optional_models:
            model_name = model_info["name"]
            model_id = model_info["id"]
            model_path = model_info["path"]
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
            if model_path.exists():
                print_success(f"âœ“ {model_name} å·²å®‰è£…")
                downloaded_models.append(model_info)
                continue
            
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            print_info("â”€" * 60)
            print_warning(f"âš ï¸  {model_name} æœªå®‰è£…")
            print_info(f"  æ¨¡å‹ ID: {model_id}")
            print_info(f"  åŠŸèƒ½: {model_info['description']}")
            print_info(f"  å¤§å°: {model_info['size']}")
            
            if model_info['size'].startswith('~1.8GB'):
                print_warning(f"  âš ï¸  è¯¥æ¨¡å‹è¾ƒå¤§ï¼Œä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
            
            print_info("")
            
            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ä¸‹è½½
            try:
                response = input(f"æ˜¯å¦ä¸‹è½½ {model_name}ï¼Ÿ(y/N): ").strip().lower()
                if response not in ['y', 'yes', 'æ˜¯']:
                    print_info(f"å·²è·³è¿‡ {model_name}")
                    skipped_models.append(model_name)
                    print_info("")
                    continue
            except (EOFError, KeyboardInterrupt):
                print_info(f"\nå·²è·³è¿‡ {model_name}")
                skipped_models.append(model_name)
                print_info("")
                continue
            
            # ä¸‹è½½æ¨¡å‹
            print_step(f"æ­£åœ¨ä¸‹è½½ {model_name}...")
            try:
                model = AutoModel(model=model_id, device="cpu")
                print_success(f"âœ… {model_name} ä¸‹è½½å®Œæˆ")
                downloaded_models.append(model_info)
                del model
            except Exception as e:
                print_error(f"âŒ {model_name} ä¸‹è½½å¤±è´¥: {e}")
                failed_models.append((model_name, str(e)))
            
            print_info("")
        
        # æ˜¾ç¤ºä¸‹è½½æ€»ç»“
        print_info("â”€" * 60)
        print_header("ä¸‹è½½æ€»ç»“")
        
        if downloaded_models:
            print_success(f"âœ… å·²å®‰è£…çš„æ¨¡å‹ ({len(downloaded_models)}):")
            for model_info in downloaded_models:
                print_success(f"  âœ“ {model_info['name']}")
            print_info("")
            
            print_info("ä¸‹ä¸€æ­¥ï¼š")
            print_info("  1. åœ¨ backend/config/core_config.json ä¸­å¯ç”¨ç›¸åº”åŠŸèƒ½:")
            for model_info in downloaded_models:
                print_info(f"     - {model_info['config_key']} = true  ({model_info['name']})")
            print_info("  2. è¿è¡Œæµ‹è¯•: python backend/test/test_funasre.py")
        
        if skipped_models:
            print_info("")
            print_warning(f"â­ï¸  è·³è¿‡çš„æ¨¡å‹ ({len(skipped_models)}):")
            for model_name in skipped_models:
                print_warning(f"  - {model_name}")
        
        if failed_models:
            print_info("")
            print_error(f"âŒ ä¸‹è½½å¤±è´¥çš„æ¨¡å‹ ({len(failed_models)}):")
            for model_name, error in failed_models:
                print_error(f"  âœ— {model_name}: {error}")
        
        if downloaded_models and not failed_models:
            print_info("")
            print_success("ğŸ‰ å¯é€‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
            return 0
        elif failed_models:
            return 1
        else:
            return 0


# =============================================================================
# å‘½ä»¤è¡Œå…¥å£
# =============================================================================

def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="çµä¾æ™ºèƒ½ä½“ç³»ç»Ÿ - æ¨¡å‹ä¸æ•°æ®ä¸€é”®å®‰è£…è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python all_ready.py                    # æ£€æµ‹å¹¶å®‰è£…æ‰€æœ‰ç¼ºå¤±çš„æ¨¡å‹
  python all_ready.py --tts-only         # ä»…æ£€æµ‹å’Œå®‰è£…TTSæ¨¡å‹
  python all_ready.py --asr-only         # ä»…æ£€æµ‹å’Œå®‰è£…ASRæ¨¡å‹
  python all_ready.py --force            # å¼ºåˆ¶é‡æ–°å®‰è£…æ‰€æœ‰æ¨¡å‹
  python all_ready.py --check-only       # ä»…æ£€æµ‹ï¼Œä¸æ‰§è¡Œä¸‹è½½
  python all_ready.py --download-emotion # ä¸‹è½½FunASRæƒ…æ„Ÿè¯†åˆ«æ¨¡å‹
  python all_ready.py --download-speaker # ä¸‹è½½FunASRè¯´è¯äººè¾¨åˆ«æ¨¡å‹

é…ç½®æ–‡ä»¶:
  - backend/config/core_config.json      # ä¸»é…ç½®æ–‡ä»¶
  - backend/config/settings.py           # é…ç½®æ¨¡å‹å®šä¹‰

æ•°æ®ç›®å½•:
  - TTS: backend/data/tts/GenieData/
  - ASR: backend/data/asr/
"""
    )
    
    parser.add_argument(
        '--tts-only',
        action='store_true',
        help='ä»…æ£€æµ‹å’Œå®‰è£…TTSæ¨¡å‹'
    )
    
    parser.add_argument(
        '--asr-only',
        action='store_true',
        help='ä»…æ£€æµ‹å’Œå®‰è£…ASRæ¨¡å‹'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶é‡æ–°å®‰è£…æ‰€æœ‰æ¨¡å‹ï¼ˆå³ä½¿å·²å­˜åœ¨ï¼‰'
    )
    
    parser.add_argument(
        '--check-only',
        action='store_true',
        help='ä»…æ£€æµ‹æ¨¡å‹çŠ¶æ€ï¼Œä¸æ‰§è¡Œä¸‹è½½'
    )
    
    parser.add_argument(
        '--download-emotion',
        action='store_true',
        help='ä¸‹è½½ FunASR æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹ (emotion2vec_plus_large, ~1.8GB)'
    )
    
    parser.add_argument(
        '--download-speaker',
        action='store_true',
        help='ä¸‹è½½ FunASR è¯´è¯äººè¾¨åˆ«æ¨¡å‹ (speech_campplus_sv_zh-cn_16k-common)'
    )
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    try:
        args = parse_args()
        manager = AllReadyManager(args)
        exit_code = manager.run()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print_warning("\nç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print_error(f"å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
